# ai_bias_checker
 AI Bias Checker üîçü§ñ AI Bias Checker is a multi-model tool designed to analyze text for potential bias, toxicity, and stereotypes using various state-of-the-art machine learning models. This project combines fine-tuned and pre-trained models to provide a comprehensive analysis of bias in text, making it a useful resource for detecting and mitigating harmful language patterns.  Features ‚ú® Multi-Model Analysis:  Fine-Tuned DistilBERT: Custom-trained on bias-related data for detecting subtle biases. d4data Bias Detection Model: Pretrained on the MBAD dataset for bias and fairness evaluation. Toxic-BERT: Specialized in detecting toxic and harmful language patterns. Rule-Based Detection: Identifies common stereotypes for enhanced manual review. Comprehensive Outputs:  Raw predictions and confidence scores from each model. Summarized results with thresholds for easier interpretation. Warnings for manual review in cases of detected bias. User-Friendly Interface:  Built with Streamlit, providing an interactive and accessible interface. Allows users to upload text files or input text directly. Customizable Thresholds:  Set detection thresholds for each model to fine-tune sensitivity to bias or toxicity.
